# -*- coding: utf-8 -*-
"""blinkDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZXkD98PqsvyXYEoj6IaunL02voVE9uZz
"""

! pip install tensorflow==2.4.1

# Import tensorflow and print current version
import tensorflow as tf
print(tf.__version__)

# Import rest of libraries used in the code. Usually this is done at the beginning of the document but it can be done at any position
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
import os
import random

theSEED = 232323
tf.random.set_seed(theSEED)
np.random.seed(theSEED)
random.seed(theSEED)

# Hyperparameters:
# They must be carefully select depending on the dataset and model

NB_EPOCH = 25       # Number of training epochs
VALIDATION_SPLIT=0.2 # Size of the validation split taken from the training set. If your dataset has validation split, skip this part.

"""Cargamos el dataset:"""

from google.colab import drive
drive.mount("/content/gdrive")

from google.colab import drive
drive.mount('/content/drive')

!mkdir -p '/content/gdrive/MyDrive/Curso-Jetson/imagenes'

!gdown --id '14CuNJzfpF-HCOcgYXE1XF0umKIxCScB7' -O '/content/gdrive/MyDrive/Curso-Jetson/imagenes/fruits.zip'

!unzip '/content/gdrive/MyDrive/Curso-Jetson/imagenes/fruits.zip' -d '/content/gdrive/MyDrive/Curso-Jetson/imagenes/'

!ls '/content/gdrive/MyDrive/Curso-Jetson/imagenes/fruits'

!ls '/content/gdrive/MyDrive/Curso-Jetson/imagenes/fruits/Training'

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/gdrive/MyDrive/Curso-Jetson/imagenes/dataset', labels='inferred', subset="training", validation_split=VALIDATION_SPLIT, seed=0)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/gdrive/MyDrive/Curso-Jetson/imagenes/dataset', labels='inferred', subset="validation", validation_split=VALIDATION_SPLIT, seed=0)

train_ds

"""Vamos a visualizar una de las muestras y la clase a la que pertenece:"""

def process(image,label):
    image = tf.image.resize(image, [224, 224])
    image = tf.cast(image/255. ,tf.float32)
    return image,label

train_ds = train_ds.map(process)
val_ds = val_ds.map(process)

#resize_and_rescale = tf.keras.Sequential([
#  tf.keras.layers.experimental.preprocessing.Resizing(224, 224),
#  tf.keras.layers.experimental.preprocessing.Rescaling(1./255)
#])

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.experimental.preprocessing.RandomFlip("horizontal_and_vertical"),
  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),
  tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),
  tf.keras.layers.experimental.preprocessing.RandomZoom((-0.2,0.2),(-0.2,0.2)),
])

# Create a pretrained model.
base_model = tf.keras.applications.MobileNetV2(
  input_tensor=None, include_top=False, 
  weights='imagenet', input_shape=(224,224,3))
base_model.trainable = False

model = tf.keras.Sequential()
#model.add(resize_and_rescale)
model.add(data_augmentation)
model.add(base_model)
model.add(tf.keras.layers.GlobalAveragePooling2D())
#model.add(tf.keras.layers.Dense(300, activation='relu'))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(100, activation='relu'))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(2, activation='softmax'))

model.build((None, 224,224,3))
model.summary()

model.layers[0].summary()

model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.02, momentum=0.9),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_ds, epochs=NB_EPOCH, validation_data=val_ds)

model.evaluate(val_ds)

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

model.layers.pop(0)
#model.layers.pop(0)
newInput = tf.keras.layers.Input(batch_shape=(None,224,224,3))
newOutputs = model(newInput)
newModel = tf.keras.Model(newInput, newOutputs)
newModel.summary()

newModel.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
newModel.evaluate(val_ds)

# Save model
OUT_MODEL_PATH= '/content/gdrive/MyDrive/Curso-Jetson/models'
model.save(os.path.join(OUT_MODEL_PATH, 'model-final-blinkDetection.hdf5'))
model.save(os.path.join(OUT_MODEL_PATH, 'model-final-blinkDetection'))

!ls $OUT_MODEL_PATH

